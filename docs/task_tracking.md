1. Setup VSCode Extension project based on [tutorial](https://code.visualstudio.com/api/get-started/your-first-extension)
2. Install Llama-CPP w/ `npm install node-llama-cpp`
3. Install CUDA Toolkit 12.2 or higher and perform associated environment variable setup
4. Downloaded a recommended model (Llama 3.2-3B-Instruct) w/ `npx --no node-llama-cpp chat`
